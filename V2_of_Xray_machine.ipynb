{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 23812,
          "sourceType": "datasetVersion",
          "datasetId": 17810
        }
      ],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/huntersarnelli/x-ray_images/blob/main/V2_of_Xray_machine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n",
        "!unzip -q chest-xray-pneumonia.zip -d /content/chest_xray\n"
      ],
      "metadata": {
        "id": "q_-hRngBKbsg",
        "outputId": "a1990669-46d0-4b46-ab56-3333d5a3abc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\n",
            "License(s): other\n",
            "Downloading chest-xray-pneumonia.zip to /content\n",
            "... resuming from 92274688 bytes (2371090747 bytes left) ...\n",
            "100% 2.29G/2.29G [01:41<00:00, 24.4MB/s]\n",
            "100% 2.29G/2.29G [01:41<00:00, 23.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/chest_xray\n"
      ],
      "metadata": {
        "id": "9FDuggqVKqUq",
        "outputId": "e952ee10-1dbd-4b78-cdc2-2c97f3c84db0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chest_xray\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#Now we set up the automation based on the path\n",
        "\n",
        "base_dir = '/content/chest_xray/chest_xray'\n",
        "\n",
        "train_dir = os.path.join(base_dir,'train')\n",
        "\n",
        "test_dir = os.path.join(base_dir,'test')\n",
        "\n",
        "validation_dir = os.path.join(base_dir,'val')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-29T22:47:39.915803Z",
          "iopub.execute_input": "2024-11-29T22:47:39.916239Z",
          "iopub.status.idle": "2024-11-29T22:47:39.923694Z",
          "shell.execute_reply.started": "2024-11-29T22:47:39.9162Z",
          "shell.execute_reply": "2024-11-29T22:47:39.922099Z"
        },
        "id": "r_1yQWPUHPai"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Now we build the data generator for the training data\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range = 20,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range =0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                 target_size=(150,150),\n",
        "                                                 batch_size=20,\n",
        "                                                 class_mode='binary')\n",
        "\n",
        "validation_generator = val_test_datagen.flow_from_directory(validation_dir,\n",
        "                                                 target_size=(150,150),\n",
        "                                                 batch_size=20,\n",
        "                                                 class_mode='binary')\n",
        "\n",
        "test_generator = val_test_datagen.flow_from_directory(test_dir,\n",
        "                                                 target_size=(150,150),\n",
        "                                                 batch_size=20,\n",
        "                                                 class_mode='binary')"
      ],
      "metadata": {
        "id": "tTRB4WHTHw4Z",
        "outputId": "7d7ee3d9-5c4e-464f-96ff-5c1d24525e76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5216 images belonging to 2 classes.\n",
            "Found 16 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(150, 150, 3)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(512, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "PfPmwQO_LZjA",
        "outputId": "73ac3002-6636-4727-b675-b09de10f06e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "\n",
        "# Adam optimizer with a learning rate scheduler\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch=100,\n",
        "                    epochs=15,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=50,\n",
        "                    callbacks=[lr_scheduler],\n",
        "                    verbose=2)\n",
        "\n"
      ],
      "metadata": {
        "id": "7dR86z1KNZU-",
        "outputId": "e84faa87-eebd-4c5b-ccd2-200e75cf1318",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 - 48s - 484ms/step - accuracy: 0.7806 - loss: 0.6049 - val_accuracy: 0.5000 - val_loss: 19.1925 - learning_rate: 0.0010\n",
            "Epoch 2/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 - 23s - 232ms/step - accuracy: 0.8450 - loss: 0.3672 - val_accuracy: 0.5000 - val_loss: 15.5677 - learning_rate: 0.0010\n",
            "Epoch 3/15\n",
            "100/100 - 13s - 131ms/step - accuracy: 0.8828 - loss: 0.2951 - val_accuracy: 0.5000 - val_loss: 5.5700 - learning_rate: 0.0010\n",
            "Epoch 4/15\n",
            "100/100 - 26s - 258ms/step - accuracy: 0.8903 - loss: 0.2813 - val_accuracy: 0.5000 - val_loss: 7.6591 - learning_rate: 0.0010\n",
            "Epoch 5/15\n",
            "100/100 - 24s - 240ms/step - accuracy: 0.9000 - loss: 0.2564 - val_accuracy: 0.5000 - val_loss: 3.0181 - learning_rate: 0.0010\n",
            "Epoch 6/15\n",
            "100/100 - 13s - 131ms/step - accuracy: 0.8803 - loss: 0.2811 - val_accuracy: 0.5000 - val_loss: 6.0674 - learning_rate: 0.0010\n",
            "Epoch 7/15\n",
            "100/100 - 26s - 258ms/step - accuracy: 0.8943 - loss: 0.2567 - val_accuracy: 0.5000 - val_loss: 35.8226 - learning_rate: 0.0010\n",
            "Epoch 8/15\n",
            "100/100 - 24s - 239ms/step - accuracy: 0.9095 - loss: 0.2462 - val_accuracy: 0.5000 - val_loss: 3.4073 - learning_rate: 1.0000e-04\n",
            "Epoch 9/15\n",
            "100/100 - 13s - 134ms/step - accuracy: 0.9016 - loss: 0.2211 - val_accuracy: 0.5000 - val_loss: 1.2571 - learning_rate: 1.0000e-04\n",
            "Epoch 10/15\n",
            "100/100 - 26s - 262ms/step - accuracy: 0.9130 - loss: 0.2270 - val_accuracy: 0.5000 - val_loss: 3.2708 - learning_rate: 1.0000e-04\n",
            "Epoch 11/15\n",
            "100/100 - 24s - 242ms/step - accuracy: 0.9125 - loss: 0.2073 - val_accuracy: 0.5000 - val_loss: 9.8376 - learning_rate: 1.0000e-04\n",
            "Epoch 12/15\n",
            "100/100 - 13s - 128ms/step - accuracy: 0.9276 - loss: 0.1733 - val_accuracy: 0.5000 - val_loss: 3.0157 - learning_rate: 1.0000e-05\n",
            "Epoch 13/15\n",
            "100/100 - 27s - 267ms/step - accuracy: 0.9230 - loss: 0.1940 - val_accuracy: 0.5625 - val_loss: 1.5436 - learning_rate: 1.0000e-05\n",
            "Epoch 14/15\n",
            "100/100 - 24s - 242ms/step - accuracy: 0.9113 - loss: 0.2142 - val_accuracy: 0.5625 - val_loss: 1.1511 - learning_rate: 1.0000e-06\n",
            "Epoch 15/15\n",
            "100/100 - 13s - 128ms/step - accuracy: 0.9328 - loss: 0.1973 - val_accuracy: 0.6250 - val_loss: 1.0067 - learning_rate: 1.0000e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_generator, steps=50)\n",
        "print(f\"Test accuracy: {test_acc*100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "iiWJR5aERT6t",
        "outputId": "15c9b5be-9e35-49d8-9eff-777c2f051e9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 96ms/step - accuracy: 0.9032 - loss: 0.2869 \n",
            "Test accuracy: 89.26%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "6cVHCLXYRd68",
        "outputId": "c1a1f228-2a30-4f6e-92b8-2fe18a919719",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/My Drive/my_model_x-ray.h5')\n"
      ],
      "metadata": {
        "id": "ZV87BxinRfG6",
        "outputId": "f6d509ef-6173-4006-faf7-f85562e2b463",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    }
  ]
}